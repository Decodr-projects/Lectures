{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blue Book for Bulldozers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "\n",
    "### Description\n",
    "\n",
    "The goal of the contest is to predict the sale price of a particular piece of heavy equiment at auction based on it's usage, equipment type, and configuaration.  \n",
    "The data is sourced from auction result postings and includes information on usage and equipment configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem definition\n",
    "\n",
    "Predict the auction sale price for a piece of heavy equipment to create a \"blue book\" for bulldozers..\n",
    "\n",
    "### Data\n",
    "\n",
    "The data is downloaded from the Kaggle Bluebook for Bulldozers competition: https://www.kaggle.com/c/bluebook-for-bulldozers/data\n",
    "\n",
    "There are 3 main datasets:\n",
    "\n",
    "    - Train.csv is the training set, which contains data through the end of 2011.\n",
    "\n",
    "    - Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of the competition. Your score on this set is used to create the public leaderboard.\n",
    "\n",
    "    - Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "The evaluation metric for this competition is the RMSLE (root mean squared log error) between the actual and predicted auction prices.\n",
    "\n",
    "For more on the evaluation of this project check: https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation\n",
    "\n",
    "Note: The goal for most regression evaluation metrics is to minimize the error. For example, our goal for this project will be to build a machine learning model which minimises RMSLE.\n",
    "\n",
    "### Features\n",
    "\n",
    "Kaggle provides a data dictionary detailing all of the features of the dataset. You can view this data dictionary on Google Sheets: https://docs.google.com/spreadsheets/d/18ly-bLR8sbDJLITkWG7ozKm8l3RyieQ2Fpgix-beSYI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the important libraries for loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the data and preparing it for modelling\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we've got our tools for data analysis ready, we can import the data and start to explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training and validation set.\n",
    "# No parse_dates... check dtype of \"saledate\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When working with time series data, it's a good idea to make sure any date data is the format of a datetime object (a Python data type which encodes specific information about dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With parse_dates... check dtype of \"saledate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort DataFrame by saledate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we're working on a time series problem and trying to predict future examples given past examples, it makes sense to sort our data by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DataFrame in date order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a copy of the original DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're going to be manipulating the data, we'll make a copy of the original DataFrame and perform our changes there.\n",
    "# This will keep the original DataFrame.\n",
    "# Make a copy of the original DataFrame to perform edits on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add datetime parameters for saledate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can enrich our dataset with as much information as possible.\n",
    "# Because we imported the data using read_csv() and we asked pandas to parse the dates using parase_dates=[\"saledate\"],\n",
    "# we can now access the different datetime attributes of the saledate column.\n",
    "# Add datetime parameters for saledate.\n",
    "# Drop original saledate.\n",
    "# Check the different values of different columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now start to do some model-driven EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This won't work since we've got missing numbers and categories,\n",
    "# Check for missing categories and different datatypes.\n",
    "# Check for missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert string to categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way we can turn all of our data into numbers is by converting them into pandas catgories.\n",
    "# We can check the different datatypes compatible with pandas here: https://pandas.pydata.org/pandas-docs/stable/reference/general_utility_functions.html#data-types-related-functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data.\n",
    "# Import preprocessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling numerical values first.\n",
    "# Check for which numeric columns have null values.\n",
    "# Fill numeric rows with the median.\n",
    "# Add a binary column which tells if the data was missing our not\n",
    "# Fill missing numeric values with median since it's more robust than the mean.\n",
    "# Check if there's any null values.\n",
    "# Check to see how many examples were missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling and turning categorical variables to numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we've filled the numeric values, we'll do the same with the categorical values at the same time as turning them into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns which *aren't* numeric.\n",
    "# Turn categorical variables into numbers.\n",
    "# Check columns which *aren't* numeric.\n",
    "# Add binary column to inidicate whether sample had missing value.\n",
    "# We add the +1 because pandas encodes missing categories as -1.\n",
    "# Fit the model.\n",
    "# Score the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation.\n",
    "# Split data into X & y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation function (the competition uses Root Mean Square Log Error)\n",
    "# Create function to evaluate our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our model on a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retraing an entire model would take far too long to continuing experimenting as fast as we want to.\n",
    "# So what we'll do is take a sample of the training set and tune the hyperparameters on that before training a larger model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain a model on training data\n",
    "# Cutting down the max number of samples each tree can see improves training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyerparameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can increase n_iter to try more combinations of hyperparameters but in our case, we'll try 20 and see where it gets us.\n",
    "# Different RandomForestClassifier hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we've got a trained model, it's time to make predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how the model goes predicting on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To get the test dataset in the same format as training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add datetime parameters for saledate.\n",
    "# Drop original saledate.\n",
    "# Fill numeric rows with the median.\n",
    "# Turn categorical variables into numbers\n",
    "# We add the +1 because pandas encodes missing categories as -1.\n",
    "# Now we got a function for preprocessing data, Now preprocess the test dataset into the same format as our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can find how the columns differ using sets.\n",
    "# Match test dataset columns to training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we've built a model which is able to make predictions.\n",
    "# Feature importance seeks to figure out which different attributes of the data were most importance when it comes to predicting the target variable (SalePrice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RandomForestRegressor for final Implementation.\n",
    "# After executing all the algorithms the RandomForestRegressor will give the better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
