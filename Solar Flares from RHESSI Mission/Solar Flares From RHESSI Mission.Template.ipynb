{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar Flares From RHESSI Mission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement: We have to predict the solar flare using the data\n",
    "\n",
    "The dataset has 113942 entries with 18 columns. The dataset is obtained from Kaggle through: https://www.kaggle.com/khsamaha/solar-flares-rhessi which was originally contributed by RHESSI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Basic Libraries\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Library for supressing warnings\n",
    "\n",
    "\n",
    "#Libraries for importing train and test set data\n",
    "\n",
    "#Libraries for doing predictions\n",
    "\n",
    "#Libraries for Decision Tree Classifier\n",
    "\n",
    "#Libraries for Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting plot display parameters \n",
    "# Use plt.rcParams to set the display parameters like 'axes.labelsize','xtick.labelsize' , 'ytick.labelsize' , 'figure.figsize'\n",
    "# Example : plt.rcParams['axes.labelsize'] = 12 \n",
    "\n",
    "\n",
    "#Set the style of the plot using set_style function in seaborn library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Dataset and Knowing the attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Pandas to read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset and displaying few records\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the information of Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describing about the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making flare ID as index and parsing dates\n",
    "\n",
    "#Read the data into new variable 'new_df' using pandas library\n",
    "\n",
    "\n",
    "# process date / time columns \n",
    "# Define a function and parse the date and time using strptime function which is imported from datetime library\n",
    "# Return the year, month and day from datex variable and hour , minute and second from timex variable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add year, month, day, start date, peak date, end date to the new data that has been read\n",
    "# Drop the earlier columns\n",
    "\n",
    "\n",
    "\n",
    "# clean columns\n",
    "\n",
    "\n",
    "# add new columns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying current columns of dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns with better names \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display few rows of new processed dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping Data wrt. to year, month and as a function of energy values using the groupby function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting 1000 rows and 4 coulmns from new dataframe into data_part for plots and finding value distribution and relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column names for data_part\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Relation between Flare duration, Peak count rate and Total count with respect to Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pairplot to plot the data_part \n",
    "# Set the parameters where hue='energy_kev' and vars='duration_s','peak_c_s' nd 'total_counts'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density Plot to visualize the distribution of the Flare wrt. Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PairGrid to plot the data_part\n",
    "# Set the parameters where hue='energy_kev' and palette='bright' and size='5' and equate that to a variable named g\n",
    "\n",
    "'''Define a function to do kdeplot with the variables x and **kwargs \n",
    "        Ex: def fun(a,**kwargs):\n",
    "            kwargs.pop(\"colour\")\n",
    "            col=next(plt.gca()._get_lines.prop_cycler)['color']\n",
    "            sns.kdeplt(a,color=col,**kwargs,linewidth=6) '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Do map_diag(fun) , map_offdiag(plt.scatter) and add_legend for g\n",
    "# Display the plot using plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countplot to Visualize distribution of flares in the different energy ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use countplot to plot the data_part\n",
    "# Set the parameters where y='energy_kev' and hue='energy_kev'\n",
    "# Add xlabel and ylabel to the graph as 'Count' and 'Energy Density Range (KeV)' with fontsize=16\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countplot on the entire dataset to verify assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use countplot to plot the new_df\n",
    "# Set the parameters where y='energy_kev' and hue='energy_kev'\n",
    "# Add Legend to the graph with title as 'Energy Range(KeV)' and parameters loc='right'and prop={'size': 10}\n",
    "# Add xlabel and ylabel to the graph as 'Count' and 'Energy Density Range (KeV)' with fontsize=16\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the relation between Energy density and Duration(in seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Distplot to plot for data_part['duration_s']\n",
    "'''Set the parameters such as kde_kws=dict(color='green', lw=3, shade=True) and \n",
    "  hist_kws=dict(alpha=1, color= 'gold', edgecolor='red', lw=3 '''\n",
    "# Add xlabel and ylabel to the graph as 'Duration in seconds' and 'Energy Density' with fontsize=16\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram and Density Curve of Flare Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equate df['duration_s_log'] as np.log(df['duration.s'])\n",
    "# Use Distplot to plot for data_part['duration_s']\n",
    "'''Set the parameters such as kde_kws=dict(color='green', lw=3, shade=True) and \n",
    "  hist_kws=dict(alpha=1, color= 'gold', edgecolor='red', lw=3 '''\n",
    "# Add xlabel and ylabel to the graph as 'Duration [log(duration.s)]' and 'Energy Density' with fontsize=16\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between Radial values and the total count of flares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the style.use function for plotting where the parameter is 'ggplot'\n",
    "# Use jointplot to plot for new_df\n",
    "'''Set the parameters such as x=new_df['radial'], y=new_df['total_counts'], color='m', kind='scatter', s=100, edgecolor=\"skyblue\", linewidth=2 '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation between Duration and log(count of flare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equate df['flare_log'] as np.log(df['duration.s'])\n",
    "# Use violinplot to plot\n",
    "'''Use parameters as x=df['energy.kev'], y=df['flare_log'], width=3, linewidth=2, hue=df['energy.kev'] '''\n",
    "# Add xlabel and ylabel to the graph as 'Count of Flares(log)' and 'Energy (KeV)' with fontsize=16\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of flares over time duration (in seconds) wrt. Energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the style.use function for plotting where the parameter is 'dark_background'\n",
    "# Use lmplot to plot\n",
    "''' Use parameters as x='duration_s', y='total_counts', hue='energy_kev', fit_reg=False, legend=True, data=new_df, palette='bright' '''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar Flares trend over the Years (2002-2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the style.use function for plotting where the parameter is 'dark_background'\n",
    "# Plot the DATA_by_yr with 'yellow' as colour and linewidth as 10\n",
    "# Add xlabel and ylabel to the graph as 'Year' and 'Solar Flare per Year' with fontsize=16\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the style.use function for plotting where the parameter is 'dark_background'\n",
    "# Plot the DATA_by_yr with 'yellow' as colour and linewidth as 10 and '8' and markersize as 20\n",
    "# Add xlabel and ylabel to the graph as 'Year' and 'Solar Flare per Year' with fontsize=16\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sunspots - Mapping Flares on the Sun\n",
    "\n",
    "#### Filtering data - removing flares having attributes null or NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Filtering data based on the energy range 3-6 KeV, flags and radial values. Filtering possible values \n",
    "    which may be wrong or without any solar event '''\n",
    "\n",
    "#Define a function with parameters as DATA and lwrong\n",
    "\n",
    "'''In the function, 1st filter is filtering 3-6 kev\n",
    "   Store the length of DATA in variable lenght1\n",
    "   Make DATA=DATA[DATA['energy.kev']!='3-6']\n",
    "   Store the length of DATA in variable lenght2\n",
    "   Do comparison that lenght1!=lenght2. If that's true print the lenght1 and lenght2'''\n",
    "\n",
    "\n",
    "''' For filtering radial, create a variable radial equating to DATA['radial'].values \n",
    "    Get length of DATA into lenght1\n",
    "    Make DATA=DATA[DATA['radial']<=np.percentile(radial,99)]\n",
    "    Then store the length of DATA in variable lenght2\n",
    "    Do comparison that lenght1!=lenght2. If that's true print the lenght1 and lenght2 '''\n",
    "\n",
    "''' For filter possible wrong values or without solar event\n",
    "    where lwrong = ['NS','SD','SS','DF','DR','ED','ES','FE','FR','FS','GD','GE','GS','MR','P0','PS','PE']\n",
    "    \n",
    "    Make a for loop such that for icod in lwrong:\n",
    "    \n",
    "    For filtering icod,  \n",
    "    Get length of DATA into lenght1\n",
    "    Make DATA=DATA[DATA['flag.1']!=icod]\n",
    "    Then store the length of DATA in variable lenght2\n",
    "    Do comparison that lenght1!=lenght2. If that's true print the %icod, lenght1 and lenght2 \n",
    "    Do the same for flag.2, flag.3, flag.4 and flag.5 in the for loop'''\n",
    "\n",
    "           \n",
    "#Then return the DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Reading dataset and filtering values based on above parameters of the function\"\"\"\n",
    "#Read the dataset using pandas into the variable data\n",
    "\n",
    "''' filtering basic '''\n",
    "#Store ['NS','SD'] into lwrong\n",
    "#Create a variable as filtered_data and store filter_data(data,lwrong)\n",
    "\n",
    "\n",
    "'''include energy bounday ranges'''\n",
    "#Store filtered_data['energy.kev'].apply(lambda col: int(col.split('-')[0])) into filtered_data['energy.kev.i']\n",
    "#Store filtered_data['energy.kev'].apply(lambda col: int(col.split('-')[1])) into filtered_data['energy.kev.f']\n",
    "\n",
    "'''Create New variable CENERGY and store filtered_data[['energy.kev','energy.kev.i','energy.kev.f']] where this has to drop\n",
    "the duplicates and the parameters has to be (inplace=False) and sort the values with\n",
    "parameters as (['energy.kev.i'], ascending=[1], inplace=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Plotting all the Flares from the filtered dataframe'''\n",
    "\n",
    "#Generate the linear spaced vectors with 0,1,len(CENERGY['energy.kev.i'].values and plot as cm.jet and store it in the variable named colors\n",
    "\n",
    "\n",
    "'''build figure object with subplots function with figsize as (10,10) and store in fig,ax'''\n",
    "\n",
    "\n",
    "'''loop over energy ranges:\n",
    "for this create a for loop as for i,irange in enumerate(CENERGY['energy.kev'].values)\n",
    "   In this loop, collect filtered data as filtered_data[filtered_data['energy.kev']==irange][['x.pos.asec','y.pos.asec']]\n",
    "        in temporary dataset in AUX_data \n",
    "   Also scatter plot to plot the flare where parameters are (AUX_data['x.pos.asec'].values,AUX_data['y.pos.asec'].values,color=colors[i],label='%s Kev'%irange)\n",
    "   Add legend to ax with parameters as (loc='best',fontsize=9,shadow=True)\n",
    "   Then delete the temporary dataset \n",
    "   Later add title to plot as SUNSPOTS per Energy\n",
    "   Then display the plot '''\n",
    "\n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flare position in the Sun arcsec from the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Y position distriution arounf the center of the sun'''\n",
    "\n",
    "# build figure object with subplots function with figsize as (10,10) and store in fig,ax\n",
    "\n",
    "\n",
    "# store filtered_data['y.pos.asec'].values into y \n",
    "\n",
    "#Plot histogram with parameters as y, bins=np.linspace(np.min(y),np.max(y),100), normed=True, label=\"label var y\", color='magenta'\n",
    "\n",
    "# set limits in ax with parameters as [np.min(y),np.max(y)] \n",
    "\n",
    "# set title as Y Position Distribution\n",
    "\n",
    "# Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yearly analysis of Flares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Number of events per year \"\"\"\n",
    "\n",
    "# Plot with the style.use function for plotting where the parameter is 'dark_background'\n",
    "# USe groupby(['year'])['total_counts'].count().plot(kind='bar',figsize=(10,2),title='YEARLY NUMBER OF EVENTS', color='magenta') for the data new_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping solar flares intensity over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Number of events per year and intensity ranges \"\"\"\n",
    "\n",
    "# calculate limits of intensity ranges:\n",
    "\n",
    "# store new_df['peak_c_s'].values into intensity\n",
    "# find np.percentile(intensity,10) and store it in p10\n",
    "# find np.percentile(intensity,50) and store it in p50\n",
    "# find np.percentile(intensity,90) and store it in 90\n",
    "\n",
    "\n",
    "# plot average of events intensity per year:\n",
    "\n",
    "# store new_df[(new_df['peak_c_s']<=p10)].groupby(['year'])['peak_c_s'].count() in PI0\n",
    "# store new_df[(new_df['peak_c_s']>p10) & (new_df['peak_c_s']<=p50)].groupby(['year'])['peak_c_s'].count() in PI1\n",
    "# store new_df[(new_df['peak_c_s']>p50) & (new_df['peak_c_s']<=p90)].groupby(['year'])['peak_c_s'].count() in PI2\n",
    "# store new_df[(new_df['peak_c_s']>p90)].groupby(['year'])['peak_c_s'].count() in PI3\n",
    "# store pd.DataFrame({'year':PI0.index.values,'very low':PI0.values,'low':PI1.values,'high':PI2.values,'very high':PI3.values}) in PI\n",
    "\n",
    "\n",
    "# build figure object with subplots function with figsize as (10,5) and store in fig,ax \n",
    "\n",
    "\n",
    "# collect data from PI0.index,PI0,PI1,PI2,PI3 and store into ind,y1,y2,y3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# make stackplot with parameters as ind, y0, y1, y2, y3, colors=['blue','green','orange','red'] with ax variable\n",
    "# set limits for ax as [ind[0]-1,ind[-1]+1]\n",
    "'''set legend for ax as \n",
    "[mpatches.Patch(color='blue'),mpatches.Patch(color='green'), mpatches.Patch(color='orange'), mpatches.Patch(color='red')], ['very low','low','high','very high']'''\n",
    "# set xlabel as Years\n",
    "# set title with YEARLY NUMBER OF EVENTS per INTENSITY (c/s)\\n (Limits Classification = %s c/s, %s c/s, %s c/s)'%(p10,p50,p90)\n",
    "# display the plot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of solar flares per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with the style.use function for plotting where the parameter is 'fivethirtyeight'\n",
    "# Use groupby(['year']['energy_kev'].value_counts().unstack().plot(kind='bar') for new_df\n",
    "# Set ylabel as 'Number of Flares', with fontsize=16\n",
    "# Set legend with parameters as title='Energy Range(KeV)', loc='best', prop={'size': 10}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting solar flare energy range from the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create predicting_df and store df.copy(deep=True)\n",
    "''' Set \n",
    "predicting_df['dt.start'] = predicting_df[['start.date','start.time']].apply(lambda x: parse_date(x[0],x[1]), axis=1)\n",
    "predicting_df['dt.peak'] = predicting_df[['start.date','peak']].apply(lambda x: parse_date(x[0],x[1]), axis=1)\n",
    "predicting_df['dt.end'] = predicting_df[['start.date','end']].apply(lambda x: parse_date(x[0],x[1]), axis=1)\n",
    "these for predicting_df '''\n",
    "# clean columns with parameters as ['start.date','start.time','peak','end'], axis=1, inplace=True\n",
    "# add new columns as year , month and day to predicting_df by using predicting_df['dt.start'].apply(lamda paramter)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display columns for predicting_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns and display few rows\n",
    "# Ex for renaming: flag.1=flag_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'flag_1', 'flag_2', 'flag_3', 'flag_4', 'flag_5', 'date_start', 'date_peak', 'date_end' columns in predicting_df with axis=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking null values for predicting_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing predicting_df object details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store predicting_df['energy_kev'].astype('category') in dt\n",
    "# use dict(enumerate()) for dt.cat.categories()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the enumerated codes which is knwon as dt.cat.codes to ernegy column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display few rows of predicting_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating train and test set for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do testtrainsplit for predicting_df with test_size=0.2 and store it in X_train and X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dsiplay the shapes of X_test and X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create y_train and store X_train['energy_kev']\n",
    "# Update X_train as X_train.drop(['energy_kev'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create y_test and store X_test['energy_kev']\n",
    "# Update X_test as X_test.drop(['energy_kev'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create decision_tree_classifier and fit the data of X_train and Y_train\n",
    "\n",
    "# Store the predicted value of X_test into decision_tree_predictions\n",
    "\n",
    "# Get the score of X_test and y_test and store it in decision_tree_score \n",
    "\n",
    "# Get the score of X_train and y_train and store it in decision_tree_score_train\n",
    "\n",
    "# Print decision_tree_score, decision_tree_score_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the classification report with y_test, decision_tree_predictions and print them\n",
    "\n",
    "# Get Precision,recall,fscore and support from y_test, decision_tree_predictions with average='micro' as parameter and print them\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random_forest_classifier and fit the data of X_train and Y_train with n_jobs=-1 as parameter\n",
    "\n",
    "# Store the predicted value of X_test into random_forest_predictions\n",
    "\n",
    "# Get the score of X_test and y_test and store it in random_forest_score\n",
    "\n",
    "# Get the score of X_train and y_train and store it in random_forest_score_train\n",
    "\n",
    "# Print random_forest_score, random_forest_score_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the classification report with y_test, random_forest_predictions and print them\n",
    "\n",
    "# Get Precision,recall,fscore and support from y_test, random_forest_predictions with average='micro' as parameter and print them\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write your inference here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
